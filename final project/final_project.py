# -*- coding: utf-8 -*-
"""final_project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E25t5UnC2lBGY7oWhFu5HtEzyqEXF9UT
"""

import numpy as np
import pandas as pd
import warnings
import matplotlib.pyplot as plt
#from IPython.core.pylabtools import figsize
#figsize(14, 7)
warnings.filterwarnings('ignore')
df = pd.read_csv("/content/drive/My Drive/road-accidents.csv", comment='#', sep='|')
X = df.iloc[:,[1,2,3,4]]

X2 = df.iloc[:,[2,3,4]]
y2 = df.iloc[:,[1]]

"""# EDA"""

df.head()

df.describe()

import seaborn as sns
plt.figure(figsize=(20,10))
sns.heatmap(X)

df.shape

df.info()

df.drvr_fatl_col_bmiles.unique()

df.drvr_fatl_col_bmiles.value_counts()

l = X.columns.values
number_of_columns=4
number_of_rows = len(l)-1/number_of_columns
plt.figure(figsize=(10,20))
for i in range(0,len(l)):
    plt.subplot(number_of_rows + 1,number_of_columns,i+1)
    sns.set_style('whitegrid')
    sns.boxplot(X[l[i]],color='green',orient='v')
    plt.tight_layout()

fig, axes = plt.subplots(nrows=2, ncols=2 , figsize=(11,6)) 
ax0, ax1, ax2, ax3 = axes.flatten()

ax0.hist(X['drvr_fatl_col_bmiles'])
ax0.set_title('drvr_fatl_col_bmiles')

ax1.hist(X['perc_fatl_1st_time'])
ax1.set_title('perc_fatl_1st_time')

ax2.hist(X['perc_fatl_alcohol'])
ax2.set_title('perc_fatl_alcohol')

ax3.hist(X['perc_fatl_speed'])
ax3.set_title('	perc_fatl_speed')

fig.tight_layout()
plt.show()

plt.figure(figsize=(20,7))
sns.countplot(df.state)
plt.xticks(rotation=90)

plt.figure(figsize=(20,7))
sns.countplot(df.drvr_fatl_col_bmiles)
plt.xticks(rotation=90)

plt.figure(figsize=(20,7))
sns.countplot(df.perc_fatl_1st_time)

plt.figure(figsize=(20,7))
sns.countplot(df.perc_fatl_alcohol)

plt.figure(figsize=(20,7))
sns.countplot(df.perc_fatl_speed)

sns.pairplot(df,diag_kind="kde")

corr = X.corr(method='pearson')
sns.heatmap(corr,annot = True)

from sklearn.model_selection import train_test_split
X_train, X_test, y_train, y_test = train_test_split(X2, y2, test_size=0.2, random_state=0)

X_train.shape , X_test.shape , y_train.shape , y_test.shape

from sklearn.linear_model import LinearRegression
regressor = LinearRegression()
regressor.fit(X_train,y_train)
#Predicting the Test set results:
y_pred= regressor.predict(X_test)
y_pred

X2.shape

df2 = df.iloc[:,[0,2,3,4]]

from sklearn.preprocessing import LabelEncoder
sc = LabelEncoder()
df2['state'] = sc.fit_transform(df2['state'])

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
df3 = sc.fit_transform(df2)

df3

"""# PCA"""

from sklearn.decomposition import PCA
pca = PCA()
df3 = pca.fit_transform(df3)

y3 = y2.to_numpy()

import matplotlib.pyplot as plt
plt.scatter(df3[:,0], df3[:,1] , c=y3 ,cmap ='plasma')
plt.xlabel('state')
plt.ylabel('perc_fatl_Speed')
plt.colorbar()

vr = pca.explained_variance_ratio_ 
vr

#cvr = np.cumsum(np.round(vr , decimals=3))
#cvr

pca.components_

plt.plot(np.cumsum(pca.explained_variance_ratio_))
plt.xlabel('number of components')
plt.ylabel('cumulative explained variance')
plt.show()

"""# scree plot"""

df5 = pd.DataFrame(df3 , columns=['state','drvr_ftl','per_speed_ftl','per_1stime_flt'])

vr

import numpy as np
import plotly.express as px

pc_df = pd.DataFrame(['state','drvr_ftl','per_speed_ftl','per_1stime_flt'], columns=['columns'])
vr_df = pd.DataFrame(vr , columns=['variance'])

main_df = pd.concat([pc_df,vr_df],axis=1)
main_df

fig = px.bar(main_df ,  x='columns',y= 'variance')
fig.show()

"""# kmeans"""

from sklearn.cluster import KMeans
kmeans = KMeans(n_clusters=3, random_state=0)
kmeans.fit(df3)

print(kmeans.cluster_centers_)

kmeans.labels_

plt.scatter(df3[:,0],df3[:,1], c=kmeans.labels_, cmap='rainbow')

distortions = []
for k in range(1,5):
    kmeanModel = KMeans(n_clusters=k, init = 'k-means++')
    kmeanModel.fit(df3)
    distortions.append(kmeanModel.inertia_)
plt.figure(figsize=(16,8))
plt.plot(K, distortions, marker='o')
plt.show()

y_kmeans = kmeans.fit_predict(df3)
y_kmeans

# Visualising the clusters
plt.scatter(df3[y_kmeans == 0, 0], df3[y_kmeans == 0, 1], c = 'red', label = 'Cluster 1')
plt.scatter(df3[y_kmeans == 1, 0], df3[y_kmeans == 1, 1], c = 'blue', label = 'Cluster 2')
plt.scatter(df3[y_kmeans == 2, 0], df3[y_kmeans == 2, 1], c = 'green', label = 'Cluster 3')
plt.title('Clusters')
plt.legend()
plt.show()

df2.columns

"""# without scaled clustering"""

#apply scaling for just clustering to make more clear visulization
y4 = sc.fit_transform(y3)

import matplotlib.pyplot as plt
plt.scatter(df2['state'], df2['perc_fatl_speed'] , c=y4 ,cmap ='plasma')
plt.xlabel('state')
plt.ylabel('perc_fatl_Speed')
plt.colorbar()

"""# with scaled clustering"""

import matplotlib.pyplot as plt
plt.scatter(df3[:,0], df3[:,1] , c=y4 ,cmap ='plasma')
plt.xlabel('state')
plt.ylabel('perc_fatl_Speed')
plt.colorbar()

"""# Compute the number of accidents within each cluster"""

new_df = pd.read_csv('/content/drive/My Drive/miles-driven.csv', sep='|')
new_df['c'] = kmeans.labels_
new_df.head()

final_df = df.merge(new_df , on='state')

final_df['drvr_fatl_col_bmiles'] = np.round(final_df['drvr_fatl_col_bmiles']).astype(int)
final_df.head()

final_df['num_drvr_fatl_col'] = final_df['drvr_fatl_col_bmiles']*final_df["million_miles_annually"]/1000

sns.barplot(x=final_df["c"], y=final_df["num_drvr_fatl_col"], data=final_df, estimator=sum, ci=None)

sns.violinplot(x=final_df["c"], y=final_df["num_drvr_fatl_col"], data=final_df)

"""Which cluster do you think should be a focus for policy intervention and further investigation?

# cluster = 1
"""